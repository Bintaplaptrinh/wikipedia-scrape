# ğŸŒ Six Degrees of Wikipedia - Extended Project

## Má»Ÿ rá»™ng Ä‘á» tÃ i

Dá»± Ã¡n nÃ y má»Ÿ rá»™ng tá»« bÃ i táº­p **Wikipedia Population Data** Ä‘á»ƒ phÃ¢n tÃ­ch **Information Influence** vÃ  **Connectivity** cá»§a cÃ¡c quá»‘c gia thÃ´ng qua Wikipedia link graph.

---

## ğŸ¯ Research Questions

### **Q4: Quá»‘c gia nÃ o cÃ³ "táº§m áº£nh hÆ°á»Ÿng thÃ´ng tin" lá»›n nháº¥t?**

**Metrics sá»­ dá»¥ng:**
- **Degree Centrality:** Sá»‘ lÆ°á»£ng connections
- **PageRank:** Importance dá»±a trÃªn incoming links
- **Betweenness Centrality:** Táº§n suáº¥t xuáº¥t hiá»‡n trÃªn shortest paths

**Hypothesis:** Large, developed countries (US, UK, China) sáº½ cÃ³ influence cao nháº¥t.

---

### **Q5: CÃ³ má»‘i tÆ°Æ¡ng quan nÃ o giá»¯a dÃ¢n sá»‘/kinh táº¿ vÃ  "má»©c Ä‘á»™ káº¿t ná»‘i"?**

**Analysis:**
- **Population vs Connectivity:** Pearson correlation
- **Density vs Connectivity:** Spearman correlation
- **Regional Patterns:** Group by Region

**Hypothesis:** 
- High population â†’ High connectivity (moderate correlation)
- Density khÃ´ng tÆ°Æ¡ng quan máº¡nh vá»›i connectivity

---

## Architecture

```
widden-question/
â”œâ”€â”€ load_data.py          # Load countries tá»« MongoDB
â”œâ”€â”€ main.py               # Main orchestrator
â”‚
â”œâ”€â”€ scrape/
â”‚   â””â”€â”€ scrape_wiki.py    # Wikipedia API scraper (multi-threaded)
â”‚
â”œâ”€â”€ bfs/
â”‚   â””â”€â”€ bfs_pathfinder.py # â­ BFS pathfinding (CORE)
â”‚
â”œâ”€â”€ analytic/
â”‚   â”œâ”€â”€ q4.py            # Influence analysis (NetworkX)
â”‚   â””â”€â”€ q5.py            # Correlation analysis (Scipy)
â”‚
â””â”€â”€ visualize/
    â””â”€â”€ visualize.py     # Plotly visualization
```

---

## Quick Start

```bash
# 1. Load countries
python load_data.py

# 2. Scrape graph
cd scrape && python scrape_wiki.py

# 3. Test BFS
cd ../bfs && python bfs_pathfinder.py

# 4. Analyze
cd ../analytic
python q4.py  # Q4: Influence
python q5.py  # Q5: Correlation

# 5. Run full pipeline
cd .. && python main.py
```

Xem chi tiáº¿t: **[QUICKSTART.md](QUICKSTART.md)**

---

## Results Preview

### **Q4: Top Influential Countries**
```
1. United States - 0.856
2. United Kingdom - 0.746
3. China - 0.723
4. France - 0.689
5. Germany - 0.654
```

### **Q5: Correlations**
```
Population vs Connectivity: r = 0.42 (p < 0.001)
â†’ en: Moderate positive correlation; vi: sá»± tÆ°Æ¡ng quan giá»¯a dáº¥n sá»‘ vÃ  má»©c Ä‘á»™ káº¿t ná»‘i

Density vs Connectivity: Ï = 0.18 (p = 0.08)
â†’ Weak correlation (not significant), sá»± tÆ°Æ¡ng quan giá»¯a máº­t Ä‘á»™ dÃ¢n sá»‘ vÃ  má»©c Ä‘á»™ káº¿t ná»‘i
```

---

## Key Features

**BFS Implementation** - Shortest path finding (CORE requirement)  
**Multi-threaded Scraping** - Fast Wikipedia data collection  
**NetworkX Analysis** - Degree, PageRank, Betweenness  
**Statistical Analysis** - Pearson & Spearman correlation  
**Interactive Visualization** - Plotly charts  

---

## Dependencies

```bash
pip install wikipediaapi networkx scipy plotly pymongo python-dotenv
```

---

## Documentation

- **[CODE_REVIEW.md](CODE_REVIEW.md)** - Bug fixes & code quality

---

## Academic Context

**Course:** Quáº£n LÃ­ Dá»¯ Liá»‡u Lá»›n  
**Topic:** Wikipedia Graph Analysis + BFS Algorithm  
**Dataset:** 232 countries + ~3000-5000 Wikipedia links  
**Techniques:** BFS, Graph Theory, Network Analysis, Statistical Correlation  

---

## Notes

- BFS lÃ  **requirement báº¯t buá»™c** vÃ  Ä‘Ã£ Ä‘Æ°á»£c implement Ä‘áº§y Ä‘á»§
- Project **KHÃ”NG dÃ¹ng Hadoop** (simplified version)
- DÃ¹ng NetworkX thay vÃ¬ implement algorithms tá»« Ä‘áº§u
- Data source: MongoDB tá»« project gá»‘c (wikipedia-scrape)